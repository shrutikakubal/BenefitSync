{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac86807f-0390-4b03-a8f9-5ee060e273e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 4)\n",
      "Index(['EmployeeID', 'BenefitID', 'SatisfactionScore', 'Comments'], dtype='object')\n",
      "624\n",
      "(29376, 4)\n",
      "EmployeeID           0\n",
      "BenefitID            0\n",
      "SatisfactionScore    0\n",
      "Comments             0\n",
      "dtype: int64\n",
      "(30, 4)\n",
      "Index(['BenefitID', 'BenefitType', 'BenefitSubType', 'BenefitCost'], dtype='object')\n",
      "0\n",
      "(30, 4)\n",
      "BenefitID         0\n",
      "BenefitType       0\n",
      "BenefitSubType    0\n",
      "BenefitCost       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feedback= pd.read_csv(\"assets/data/feedback_data.csv\")\n",
    "benefits= pd.read_csv(\"assets/data/benefits_data.csv\")\n",
    "\n",
    "def clean(df):\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    print(df.duplicated().sum())\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(df.shape)\n",
    "    print(df.isna().sum())\n",
    "\n",
    "clean(feedback)\n",
    "clean(benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ba89249-7adf-4979-9ede-e7fece74cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "            langchain-openai==0.3.3 \\\n",
    "            langchain==0.3.17 \\\n",
    "            textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff97b85a-7f18-44e0-9265-75f3514f1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api.txt', 'r') as file:\n",
    "    OPENAI_API_KEY = file.read().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54094bcc-ad95-472d-b25d-1d6f8c5f6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29376, 6)\n",
      "Index(['EmployeeID', 'BenefitID', 'SatisfactionScore', 'Comments',\n",
      "       'BenefitType', 'BenefitSubType'],\n",
      "      dtype='object')\n",
      "0\n",
      "(29376, 6)\n",
      "EmployeeID           0\n",
      "BenefitID            0\n",
      "SatisfactionScore    0\n",
      "Comments             0\n",
      "BenefitType          0\n",
      "BenefitSubType       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(\n",
    "    feedback,\n",
    "    benefits[['BenefitID', 'BenefitType', 'BenefitSubType']],\n",
    "    on='BenefitID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da45ed5-0306-4fe1-9521-f679ebadd23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenefitTypes: ['Gym Membership' 'Tuition Reimbursement' 'Commuter Benefits'\n",
      " 'Life Insurance' 'Retirement Plan' 'Health Insurance'\n",
      " 'Cell Phone Allowance' 'Flexible Spending Account' 'Wellness Programs'\n",
      " 'Childcare' 'Professional Development' 'Technology Stipend']\n",
      "BenefitSubTypes: ['Tier 2 Partners' 'Undergraduate Degree' 'Transit Subsidy'\n",
      " 'Supplemental Standard' '401k Basic Matching' '401k Investment Fees'\n",
      " 'Individual Courses' 'Dependent Coverage' 'Basic Coverage'\n",
      " 'Tier 3 Partners' 'HMO Family' 'PPO Family' '401k Catch-Up Contributions'\n",
      " 'PPO Individual' 'Monthly Communications' 'HDHP Individual'\n",
      " 'Healthcare FSA' 'Premium Discount Tier 1' 'After-School Care'\n",
      " 'Graduate Degree' 'On-Site Infant Care' 'Conference Attendance'\n",
      " 'Family Membership' 'Monthly Internet Allowance' 'Tier 1 Partners'\n",
      " '401k Standard Matching' 'Professional Certification'\n",
      " 'Supplemental High Amount' '401k Maximum Matching'\n",
      " '401k High Contribution']\n"
     ]
    }
   ],
   "source": [
    "print(f\"BenefitTypes: {df['BenefitType'].unique()}\")\n",
    "print(f\"BenefitSubTypes: {df['BenefitSubType'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78b92dac-f06d-446d-b012-ceee12652c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Difference to run normally: 23.6418879032135\n",
      "✅ Processed feedback saved to 'feedback_chained_output.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# LangChain setup\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# === Load Feedback Data ===\n",
    "df_normal = df.head(10)  # limit for testing\n",
    "\n",
    "# === Step 1: Feedback Classification ===\n",
    "classify_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Classify the following employee comment into **one of the categories** below.\n",
    "Also consider specific benefit types and subtypes mentioned, such as Gym Membership, Tuition Reimbursement, Health Insurance, etc.\n",
    "\n",
    "Choose ONLY ONE category from the list:\n",
    "\n",
    "1. Process Issues — Problems with how a benefit is applied for, claimed, or managed (e.g., reimbursement delays)\n",
    "2. Coverage Issues — Complaints about what is or isn’t covered under the benefit plan\n",
    "3. Benefit Value — Perceptions about whether the benefit is worth it or meets employee needs\n",
    "4. Enrollment & Access Issues — Difficulty enrolling, accessing, or navigating benefit platforms\n",
    "5. Communication & Clarity — Confusion due to unclear terms, poor documentation, or lack of information\n",
    "6. Provider Specific Complaints — Complaints aimed at third-party providers (e.g., gym partners, HMO networks)\n",
    "7. Other  — Does not clearly fit in the above categories\n",
    "\n",
    "Respond with only the category name.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "\"\"\")\n",
    "\n",
    "classify_chain = classify_prompt | llm | parser\n",
    "\n",
    "# === Step 2: Action Identification ===\n",
    "action_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the comment,benefittype, benefitsubtype, category, sentiment, and severity, determine if this issue requires action.\n",
    "If yes, summarize the action briefly in a sentence or less.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "Category: {category}\n",
    "Sentiment: {sentiment}\n",
    "Severity: {severity}\n",
    "\n",
    "Return:\n",
    "Actionable: Yes/No\n",
    "Suggested Action: <action or 'None'>\n",
    "\"\"\")\n",
    "action_chain = action_prompt | llm | parser\n",
    "\n",
    "# === Step 3: Task Routing ===\n",
    "route_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Route this issue to the correct department and assign a priority level.\n",
    "\n",
    "Inputs:\n",
    "- Category: {category}\n",
    "- BenefitType: {BenefitType}\n",
    "- BenefitSubType: {BenefitSubType}\n",
    "- Suggested Action: {suggested_action}\n",
    "- Severity: {severity}\n",
    "\n",
    "Output format:\n",
    "Department: <department>\n",
    "Priority: <High/Medium/Low>\n",
    "\"\"\")\n",
    "route_chain = route_prompt | llm | parser\n",
    "\n",
    "\n",
    "# === Step 4: Issue Summary ===\n",
    "issue_summary_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Summarize the employee's issue clearly and concisely in one sentence, using the inputs below.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "Category: {category}\n",
    "Sentiment: {sentiment}\n",
    "Severity: {severity}\n",
    "Suggested Action: {suggested_action}\n",
    "\n",
    "Return:\n",
    "<One-sentence issue summary>\n",
    "\"\"\")\n",
    "issue_summary_chain = issue_summary_prompt | llm | parser\n",
    "\n",
    "\n",
    "# === Sentiment Analysis using TextBlob ===\n",
    "def analyze_sentiment(comment: str):\n",
    "    try:\n",
    "        if not comment or not isinstance(comment, str):\n",
    "            return \"Neutral\", 3  # Default fallback\n",
    "\n",
    "        blob = TextBlob(comment)\n",
    "        polarity = blob.sentiment.polarity  # Ranges from -1 to 1\n",
    "        subjectivity = blob.sentiment.subjectivity  # Ranges from 0 to 1\n",
    "\n",
    "        # Sentiment label\n",
    "        if polarity >= 0.3:\n",
    "            sentiment = \"Positive\"\n",
    "        elif polarity <= -0.3:\n",
    "            sentiment = \"Negative\"\n",
    "        else:\n",
    "            sentiment = \"Neutral\"\n",
    "\n",
    "        # Granular severity mapping\n",
    "        if polarity >= 0.6:\n",
    "            severity = 1  # Very positive\n",
    "        elif polarity >= 0.3:\n",
    "            severity = 2  # Mild positive\n",
    "        elif polarity > -0.3:\n",
    "            severity = 3  # Neutral\n",
    "        elif polarity > -0.6:\n",
    "            severity = 4  # Mild negative\n",
    "        else:\n",
    "            severity = 5  # Very negative\n",
    "\n",
    "        # Adjust for very vague/unopinionated comments\n",
    "        if subjectivity < 0.2 and sentiment == \"Neutral\":\n",
    "            severity = 2  # Informational, not severe\n",
    "\n",
    "        return sentiment, severity\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Sentiment Error]: {e}\")\n",
    "        return \"Neutral\", 3\n",
    "\n",
    "\n",
    "# === Process Each Feedback Comment ===\n",
    "results = []\n",
    "import time\n",
    "start_time= time.time()\n",
    "for _, row in tqdm(df_normal.iterrows(), total=len(df_normal)):\n",
    "    comment = row[\"Comments\"]\n",
    "    employee_id = row[\"EmployeeID\"]\n",
    "    benefit_id = row[\"BenefitID\"]\n",
    "    BenefitType = row['BenefitType']\n",
    "    BenefitSubType = row['BenefitSubType']\n",
    "    # Step 1: Category Classification\n",
    "    category = classify_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType}).strip()\n",
    "\n",
    "    # Step 2: Sentiment Analysis (local NLP)\n",
    "    sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "    # Step 3: Action Identification\n",
    "    action_output = action_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"category\": category,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"severity\": severity\n",
    "    })\n",
    "    actionable, suggested_action = \"No\", \"None\"\n",
    "    if \"Actionable:\" in action_output:\n",
    "        parts = action_output.split(\"Suggested Action:\")\n",
    "        actionable = parts[0].split(\":\")[1].strip()\n",
    "        suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "    # Step 4: Task Routing\n",
    "    route_output = route_chain.invoke({\n",
    "        \"category\": category,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"suggested_action\": suggested_action,\n",
    "        \"severity\": severity\n",
    "    })\n",
    "    try:\n",
    "        lines = route_output.split(\"\\n\")\n",
    "        department = lines[0].split(\":\")[1].strip()\n",
    "        priority = lines[1].split(\":\")[1].strip()\n",
    "    except:\n",
    "        department = \"Unknown\"\n",
    "        issue_summary = \"Parsing error\"\n",
    "        priority = \"Medium\"\n",
    "\n",
    "    # Step 5: Generate Issue Summary\n",
    "    issue_summary = issue_summary_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"category\": category,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"severity\": severity,\n",
    "        \"suggested_action\": suggested_action\n",
    "    }).strip()\n",
    "\n",
    "    # Add to results\n",
    "    results.append({\n",
    "        \"EmployeeID\": employee_id,\n",
    "        \"BenefitID\": benefit_id,\n",
    "        \"Comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"Category\": category,\n",
    "        \"Sentiment\": sentiment,\n",
    "        \"Severity\": severity,\n",
    "        \"Actionable\": actionable,\n",
    "        \"SuggestedAction\": suggested_action,\n",
    "        \"Department\": department,\n",
    "        \"Priority\": priority,\n",
    "        \"IssueSummary\": issue_summary\n",
    "    })\n",
    "end_time= time.time()\n",
    "print(f\"The Time Difference to run normally: {end_time- start_time}\")\n",
    "# Save final results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"feedback_chained_output.csv\", index=False)\n",
    "print(\"✅ Processed feedback saved to 'feedback_chained_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0b16b-bf4c-4553-8471-64fa7f1fe281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set up your chains\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"Category\": classify_chain,\n",
    "    \"ActionResult\": action_chain,\n",
    "    \"Routing\": route_chain,\n",
    "    \"IssueSummary\": issue_summary_chain\n",
    "})\n",
    "\n",
    "SAVE_INTERVAL = 1000  # Save after every 100 rows\n",
    "OUTPUT_FILE = \"feedback_parallel_output_iter2.csv\"\n",
    "\n",
    "# === Robust Row Processor ===\n",
    "def process_row_parallel(row):\n",
    "    try:\n",
    "        comment = row[\"Comments\"]\n",
    "        employee_id = row[\"EmployeeID\"]\n",
    "        benefit_id = row[\"BenefitID\"]\n",
    "        BenefitType = row[\"BenefitType\"]\n",
    "        BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "        # Step 1: Sentiment\n",
    "        sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "        input_dict = {\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"severity\": severity,\n",
    "            \"category\": \"Unknown\",\n",
    "            \"suggested_action\": \"None\"\n",
    "        }\n",
    "\n",
    "        # Step 2: Classify (separate try to isolate LLM failure)\n",
    "        try:\n",
    "            category = classify_chain.invoke({\n",
    "                \"comments\": comment,\n",
    "                \"BenefitType\": BenefitType,\n",
    "                \"BenefitSubType\": BenefitSubType\n",
    "            }).strip()\n",
    "            input_dict[\"category\"] = category\n",
    "        except Exception as e:\n",
    "            return {\"EmployeeID\": employee_id, \"Error\": f\"Category error: {e}\"}\n",
    "\n",
    "        # Step 3: Run all in parallel\n",
    "        try:\n",
    "            output = parallel_chain.invoke(input_dict)\n",
    "        except Exception as e:\n",
    "            return {\"EmployeeID\": employee_id, \"Error\": f\"Parallel chain error: {e}\"}\n",
    "\n",
    "        # Parse ActionResult\n",
    "        action_output = output.get(\"ActionResult\", \"\")\n",
    "        actionable, suggested_action = \"No\", \"None\"\n",
    "        if \"Actionable:\" in action_output:\n",
    "            parts = action_output.split(\"Suggested Action:\")\n",
    "            actionable = parts[0].split(\":\")[1].strip()\n",
    "            suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "        input_dict[\"suggested_action\"] = suggested_action\n",
    "\n",
    "        # Re-run dependent chains\n",
    "        try:\n",
    "            routing_result = route_chain.invoke(input_dict)\n",
    "            lines = routing_result.split(\"\\n\")\n",
    "            department = lines[0].split(\":\")[1].strip() if len(lines) > 0 else \"Unknown\"\n",
    "            priority = lines[1].split(\":\")[1].strip() if len(lines) > 1 else \"Medium\"\n",
    "        except Exception as e:\n",
    "            department, priority = \"Unknown\", \"Medium\"\n",
    "\n",
    "        try:\n",
    "            issue_summary = issue_summary_chain.invoke(input_dict).strip()\n",
    "        except Exception as e:\n",
    "            issue_summary = \"Summary generation error\"\n",
    "\n",
    "        return {\n",
    "            \"EmployeeID\": employee_id,\n",
    "            \"BenefitID\": benefit_id,\n",
    "            \"Comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"Category\": category,\n",
    "            \"Sentiment\": sentiment,\n",
    "            \"Severity\": severity,\n",
    "            \"Actionable\": actionable,\n",
    "            \"SuggestedAction\": suggested_action,\n",
    "            \"Department\": department,\n",
    "            \"Priority\": priority,\n",
    "            \"IssueSummary\": issue_summary\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"EmployeeID\": row.get(\"EmployeeID\", \"Unknown\"), \"Error\": f\"Fatal row error: {e}\"}\n",
    "\n",
    "\n",
    "df_parallel = df\n",
    "rows = [row for _, row in df_parallel.iterrows()]\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "        for i, future in enumerate(tqdm(as_completed(futures), total=len(futures))):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "            # Save checkpoint every N rows\n",
    "            if i % SAVE_INTERVAL == 0 and i > 0:\n",
    "                checkpoint_df = pd.DataFrame(results)\n",
    "                checkpoint_df.to_csv(OUTPUT_FILE, index=False)\n",
    "                print(f\"🔸 Checkpoint saved at row {i}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Parallel processing failed: {e}\")\n",
    "    # Save whatever was done so far\n",
    "    pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"⚠️ Partial results saved after crash.\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"⏱️ Time Taken: {end - start:.2f} seconds\")\n",
    "\n",
    "# Final save\n",
    "pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False)\n",
    "print(\"✅ Final results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab449de-8219-4297-bfb4-48114e45a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5514/29376 [27:43<1:24:11,  4.72it/s]"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"Category\": classify_chain,\n",
    "    \"ActionResult\": action_chain,\n",
    "    \"Routing\": route_chain,\n",
    "    \"IssueSummary\": issue_summary_chain\n",
    "})\n",
    "\n",
    "\n",
    "def process_row_parallel(row):\n",
    "    try:\n",
    "        comment = row[\"Comments\"]\n",
    "        employee_id = row[\"EmployeeID\"]\n",
    "        benefit_id = row[\"BenefitID\"]\n",
    "        BenefitType = row[\"BenefitType\"]\n",
    "        BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "        sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "        input_dict = {\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"severity\": severity,\n",
    "            \"category\": \"Unknown\",           # Needed by action_chain\n",
    "            \"suggested_action\": \"None\"       # Needed by route_chain & summary\n",
    "        }\n",
    "\n",
    "        # Classify first to get category\n",
    "        category = classify_chain.invoke({\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType\n",
    "        }).strip()\n",
    "        input_dict[\"category\"] = category\n",
    "\n",
    "        # Now run the rest in parallel\n",
    "        output = parallel_chain.invoke(input_dict)\n",
    "\n",
    "        # Parse action result\n",
    "        action_output = output.get(\"ActionResult\", \"\")\n",
    "        actionable, suggested_action = \"No\", \"None\"\n",
    "        if \"Actionable:\" in action_output:\n",
    "            parts = action_output.split(\"Suggested Action:\")\n",
    "            actionable = parts[0].split(\":\")[1].strip()\n",
    "            suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "        # Update for final prompt pieces\n",
    "        input_dict[\"suggested_action\"] = suggested_action\n",
    "\n",
    "        # Re-run route and summary with full data\n",
    "        routing_result = route_chain.invoke(input_dict)\n",
    "        issue_summary = issue_summary_chain.invoke(input_dict)\n",
    "\n",
    "        # Parse routing\n",
    "        lines = routing_result.split(\"\\n\")\n",
    "        department = lines[0].split(\":\")[1].strip() if len(lines) > 0 else \"Unknown\"\n",
    "        priority = lines[1].split(\":\")[1].strip() if len(lines) > 1 else \"Medium\"\n",
    "\n",
    "        return {\n",
    "            \"EmployeeID\": employee_id,\n",
    "            \"BenefitID\": benefit_id,\n",
    "            \"Comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"Category\": category,\n",
    "            \"Sentiment\": sentiment,\n",
    "            \"Severity\": severity,\n",
    "            \"Actionable\": actionable,\n",
    "            \"SuggestedAction\": suggested_action,\n",
    "            \"Department\": department,\n",
    "            \"Priority\": priority,\n",
    "            \"IssueSummary\": issue_summary.strip()\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "df_parallel = df\n",
    "rows = [row for _, row in df_parallel.iterrows()]\n",
    "results = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        result = future.result()\n",
    "        results.append(result)\n",
    "end = time.time()\n",
    "print(f\"The Time Taken to run in parallel:  {end- start}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"feedback_parallel_output.csv\", index=False)\n",
    "print(\"✅ Done! Results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc737bb-b955-4517-bade-1afcbb055501",
   "metadata": {},
   "source": [
    "### Normal Processing: \n",
    "For 25 Feedbacks - 140 Seconds and 5.60 sec / iteration\n",
    "\n",
    "### Parallel Processing: \n",
    "For 50 Feedbacks - 24.7 Seconds and 2.02 sec / iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cc19e-469f-4f4c-b635-d67def0b9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# def process_row_parallel(row):\n",
    "#     try:\n",
    "#         comment = row[\"Comments\"]\n",
    "#         employee_id = row[\"EmployeeID\"]\n",
    "#         benefit_id = row[\"BenefitID\"]\n",
    "#         BenefitType = row[\"BenefitType\"]\n",
    "#         BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "#         # 1. Local sentiment analysis\n",
    "#         sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "#         # 2. Input to all chains\n",
    "#         shared_input = {\n",
    "#             \"comments\": comment,\n",
    "#             \"BenefitType\": BenefitType,\n",
    "#             \"BenefitSubType\": BenefitSubType,\n",
    "#             \"sentiment\": sentiment,\n",
    "#             \"severity\": severity,\n",
    "#             # suggested_action is not yet known (circular)\n",
    "#         }\n",
    "#         from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "#         parallel_chain = RunnableParallel({\n",
    "#             \"Category\": classify_chain,\n",
    "#             \"ActionResult\": action_chain,\n",
    "#             \"Routing\": route_chain,\n",
    "#             \"IssueSummary\": issue_summary_chain\n",
    "#         })\n",
    "\n",
    "#         # 3. Run all chains in parallel\n",
    "#         output = parallel_chain.invoke(shared_input)\n",
    "\n",
    "#         # Unpack results\n",
    "#         category = output.get(\"Category\", \"Other\").strip()\n",
    "#         action_result = output.get(\"ActionResult\", \"\").strip()\n",
    "#         routing_result = output.get(\"Routing\", \"\").strip()\n",
    "#         issue_summary = output.get(\"IssueSummary\", \"\").strip()\n",
    "\n",
    "#         # Parse Actionable & Suggested Action\n",
    "#         actionable, suggested_action = \"No\", \"None\"\n",
    "#         if \"Actionable:\" in action_result:\n",
    "#             parts = action_result.split(\"Suggested Action:\")\n",
    "#             actionable = parts[0].split(\":\")[1].strip()\n",
    "#             suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "#         # Parse Department & Priority\n",
    "#         department = \"Unknown\"\n",
    "#         priority = \"Medium\"\n",
    "#         lines = routing_result.split(\"\\n\")\n",
    "#         if len(lines) >= 2:\n",
    "#             department = lines[0].split(\":\")[1].strip()\n",
    "#             priority = lines[1].split(\":\")[1].strip()\n",
    "\n",
    "#         return {\n",
    "#             \"EmployeeID\": employee_id,\n",
    "#             \"BenefitID\": benefit_id,\n",
    "#             \"Comments\": comment,\n",
    "#             \"BenefitType\": BenefitType,\n",
    "#             \"BenefitSubType\": BenefitSubType,\n",
    "#             \"Category\": category,\n",
    "#             \"Sentiment\": sentiment,\n",
    "#             \"Severity\": severity,\n",
    "#             \"Actionable\": actionable,\n",
    "#             \"SuggestedAction\": suggested_action,\n",
    "#             \"Department\": department,\n",
    "#             \"Priority\": priority,\n",
    "#             \"IssueSummary\": issue_summary\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return {\"Error\": str(e)}\n",
    "\n",
    "# df= df.head(50)\n",
    "# rows = [row for _, row in df.iterrows()]\n",
    "# results = []\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#     futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "#     for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "#         result = future.result()\n",
    "#         results.append(result)\n",
    "# end = time.time()\n",
    "# print(f\"The Time Taken to run in parallel:  {end- start}\")\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"feedback_parallel_output.csv\", index=False)\n",
    "# print(\"✅ Done! Results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3f739-1366-4e6f-9b0e-36ccd68bf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ab1f4-f4e1-4707-bc65-0f737e03326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42726a2-4a85-4307-8317-6e427a895b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['SuggestedAction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0e9c8-620c-4cf9-9862-99e70c0c65a4",
   "metadata": {},
   "source": [
    "### Testing the Generated Parallel Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed94e015-301c-4a45-ba30-c29d5128b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29376, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"feedback_parallel_output.csv\")\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "874002fc-3c1c-4c81-bb03-47e332858f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories: ['Benefit Value' 'Other' 'Process Issues' 'Provider Specific Complaints'\n",
      " 'Coverage Issues' 'Enrollment & Access Issues']\n",
      "Unique Sentiments: ['Positive' 'Neutral' 'Negative']\n",
      "Unique Severity: [2 1 3 4 5]\n",
      "Unique Actionables: ['No' 'Yes']\n",
      "Unique Departments: ['Benefits Administration' 'Human Resources' 'Customer Service'\n",
      " 'Life Insurance Coverage Department' 'Health Insurance Coverage'\n",
      " 'Childcare Services' 'Enrollment & Access' 'Retirement Benefits'\n",
      " 'Professional Development' 'Wellness Programs'\n",
      " 'Life Insurance Department' 'Health Insurance Coverage Team'\n",
      " 'Health Insurance Coverage Department' 'Provider Relations' 'IT Support'\n",
      " 'Finance' 'Life Insurance Coverage Team' 'Commuter Benefits Department'\n",
      " 'Enrollment & Access Issues' 'Health Insurance Claims'\n",
      " 'Benefits Management' 'Life Insurance Claims' 'Health Insurance Support'\n",
      " 'Commuter Benefits Administration']\n",
      "Unique Priority: ['Medium' 'High']\n",
      "----------------------------------------------------------\n",
      "Unique Count of SuggestedAction: 296\n",
      "Unique Count of IssueSummary: 1033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique Categories: {df['Category'].unique()}\")\n",
    "print(f\"Unique Sentiments: {df['Sentiment'].unique()}\")\n",
    "print(f\"Unique Severity: {df['Severity'].unique()}\")\n",
    "print(f\"Unique Actionables: {df['Actionable'].unique()}\")\n",
    "print(f\"Unique Departments: {df['Department'].unique()}\")\n",
    "print(f\"Unique Priority: {df['Priority'].unique()}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"Unique Count of SuggestedAction: {df['SuggestedAction'].nunique()}\")\n",
    "print(f\"Unique Count of IssueSummary: {df['IssueSummary'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "874148c5-4fac-4abb-bb78-956d34b71393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID             0\n",
      "BenefitID              0\n",
      "Comments               0\n",
      "BenefitType            0\n",
      "BenefitSubType         0\n",
      "Category               0\n",
      "Sentiment              0\n",
      "Severity               0\n",
      "Actionable             0\n",
      "SuggestedAction    13385\n",
      "Department             0\n",
      "Priority               0\n",
      "IssueSummary           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
