{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac86807f-0390-4b03-a8f9-5ee060e273e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 4)\n",
      "Index(['EmployeeID', 'BenefitID', 'SatisfactionScore', 'Comments'], dtype='object')\n",
      "624\n",
      "(29376, 4)\n",
      "EmployeeID           0\n",
      "BenefitID            0\n",
      "SatisfactionScore    0\n",
      "Comments             0\n",
      "dtype: int64\n",
      "(30, 4)\n",
      "Index(['BenefitID', 'BenefitType', 'BenefitSubType', 'BenefitCost'], dtype='object')\n",
      "0\n",
      "(30, 4)\n",
      "BenefitID         0\n",
      "BenefitType       0\n",
      "BenefitSubType    0\n",
      "BenefitCost       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feedback= pd.read_csv(\"assets/data/feedback_data.csv\")\n",
    "benefits= pd.read_csv(\"assets/data/benefits_data.csv\")\n",
    "\n",
    "def clean(df):\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    print(df.duplicated().sum())\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(df.shape)\n",
    "    print(df.isna().sum())\n",
    "\n",
    "clean(feedback)\n",
    "clean(benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ba89249-7adf-4979-9ede-e7fece74cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "            langchain-openai==0.3.3 \\\n",
    "            langchain==0.3.17 \\\n",
    "            textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff97b85a-7f18-44e0-9265-75f3514f1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api.txt', 'r') as file:\n",
    "    OPENAI_API_KEY = file.read().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54094bcc-ad95-472d-b25d-1d6f8c5f6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29376, 6)\n",
      "Index(['EmployeeID', 'BenefitID', 'SatisfactionScore', 'Comments',\n",
      "       'BenefitType', 'BenefitSubType'],\n",
      "      dtype='object')\n",
      "0\n",
      "(29376, 6)\n",
      "EmployeeID           0\n",
      "BenefitID            0\n",
      "SatisfactionScore    0\n",
      "Comments             0\n",
      "BenefitType          0\n",
      "BenefitSubType       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(\n",
    "    feedback,\n",
    "    benefits[['BenefitID', 'BenefitType', 'BenefitSubType']],\n",
    "    on='BenefitID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da45ed5-0306-4fe1-9521-f679ebadd23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenefitTypes: ['Gym Membership' 'Tuition Reimbursement' 'Commuter Benefits'\n",
      " 'Life Insurance' 'Retirement Plan' 'Health Insurance'\n",
      " 'Cell Phone Allowance' 'Flexible Spending Account' 'Wellness Programs'\n",
      " 'Childcare' 'Professional Development' 'Technology Stipend']\n",
      "BenefitSubTypes: ['Tier 2 Partners' 'Undergraduate Degree' 'Transit Subsidy'\n",
      " 'Supplemental Standard' '401k Basic Matching' '401k Investment Fees'\n",
      " 'Individual Courses' 'Dependent Coverage' 'Basic Coverage'\n",
      " 'Tier 3 Partners' 'HMO Family' 'PPO Family' '401k Catch-Up Contributions'\n",
      " 'PPO Individual' 'Monthly Communications' 'HDHP Individual'\n",
      " 'Healthcare FSA' 'Premium Discount Tier 1' 'After-School Care'\n",
      " 'Graduate Degree' 'On-Site Infant Care' 'Conference Attendance'\n",
      " 'Family Membership' 'Monthly Internet Allowance' 'Tier 1 Partners'\n",
      " '401k Standard Matching' 'Professional Certification'\n",
      " 'Supplemental High Amount' '401k Maximum Matching'\n",
      " '401k High Contribution']\n"
     ]
    }
   ],
   "source": [
    "print(f\"BenefitTypes: {df['BenefitType'].unique()}\")\n",
    "print(f\"BenefitSubTypes: {df['BenefitSubType'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78b92dac-f06d-446d-b012-ceee12652c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Difference to run normally: 23.6418879032135\n",
      "‚úÖ Processed feedback saved to 'feedback_chained_output.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# LangChain setup\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# === Load Feedback Data ===\n",
    "df_normal = df.head(10)  # limit for testing\n",
    "\n",
    "# === Step 1: Feedback Classification ===\n",
    "classify_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Classify the following employee comment into **one of the categories** below.\n",
    "Also consider specific benefit types and subtypes mentioned, such as Gym Membership, Tuition Reimbursement, Health Insurance, etc.\n",
    "\n",
    "Choose ONLY ONE category from the list:\n",
    "\n",
    "1. Process Issues ‚Äî Problems with how a benefit is applied for, claimed, or managed (e.g., reimbursement delays)\n",
    "2. Coverage Issues ‚Äî Complaints about what is or isn‚Äôt covered under the benefit plan\n",
    "3. Benefit Value ‚Äî Perceptions about whether the benefit is worth it or meets employee needs\n",
    "4. Enrollment & Access Issues ‚Äî Difficulty enrolling, accessing, or navigating benefit platforms\n",
    "5. Communication & Clarity ‚Äî Confusion due to unclear terms, poor documentation, or lack of information\n",
    "6. Provider Specific Complaints ‚Äî Complaints aimed at third-party providers (e.g., gym partners, HMO networks)\n",
    "7. Other  ‚Äî Does not clearly fit in the above categories\n",
    "\n",
    "Respond with only the category name.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "\"\"\")\n",
    "\n",
    "classify_chain = classify_prompt | llm | parser\n",
    "\n",
    "# === Step 2: Action Identification ===\n",
    "action_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the comment,benefittype, benefitsubtype, category, sentiment, and severity, determine if this issue requires action.\n",
    "If yes, summarize the action briefly in a sentence or less.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "Category: {category}\n",
    "Sentiment: {sentiment}\n",
    "Severity: {severity}\n",
    "\n",
    "Return:\n",
    "Actionable: Yes/No\n",
    "Suggested Action: <action or 'None'>\n",
    "\"\"\")\n",
    "action_chain = action_prompt | llm | parser\n",
    "\n",
    "# === Step 3: Task Routing ===\n",
    "route_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Route this issue to the correct department and assign a priority level.\n",
    "\n",
    "Inputs:\n",
    "- Category: {category}\n",
    "- BenefitType: {BenefitType}\n",
    "- BenefitSubType: {BenefitSubType}\n",
    "- Suggested Action: {suggested_action}\n",
    "- Severity: {severity}\n",
    "\n",
    "Output format:\n",
    "Department: <department>\n",
    "Priority: <High/Medium/Low>\n",
    "\"\"\")\n",
    "route_chain = route_prompt | llm | parser\n",
    "\n",
    "\n",
    "# === Step 4: Issue Summary ===\n",
    "issue_summary_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Summarize the employee's issue clearly and concisely in one sentence, using the inputs below.\n",
    "\n",
    "Comment: {comments}\n",
    "BenefitType: {BenefitType}\n",
    "BenefitSubType: {BenefitSubType}\n",
    "Category: {category}\n",
    "Sentiment: {sentiment}\n",
    "Severity: {severity}\n",
    "Suggested Action: {suggested_action}\n",
    "\n",
    "Return:\n",
    "<One-sentence issue summary>\n",
    "\"\"\")\n",
    "issue_summary_chain = issue_summary_prompt | llm | parser\n",
    "\n",
    "\n",
    "# === Sentiment Analysis using TextBlob ===\n",
    "def analyze_sentiment(comment: str):\n",
    "    try:\n",
    "        if not comment or not isinstance(comment, str):\n",
    "            return \"Neutral\", 3  # Default fallback\n",
    "\n",
    "        blob = TextBlob(comment)\n",
    "        polarity = blob.sentiment.polarity  # Ranges from -1 to 1\n",
    "        subjectivity = blob.sentiment.subjectivity  # Ranges from 0 to 1\n",
    "\n",
    "        # Sentiment label\n",
    "        if polarity >= 0.3:\n",
    "            sentiment = \"Positive\"\n",
    "        elif polarity <= -0.3:\n",
    "            sentiment = \"Negative\"\n",
    "        else:\n",
    "            sentiment = \"Neutral\"\n",
    "\n",
    "        # Granular severity mapping\n",
    "        if polarity >= 0.6:\n",
    "            severity = 1  # Very positive\n",
    "        elif polarity >= 0.3:\n",
    "            severity = 2  # Mild positive\n",
    "        elif polarity > -0.3:\n",
    "            severity = 3  # Neutral\n",
    "        elif polarity > -0.6:\n",
    "            severity = 4  # Mild negative\n",
    "        else:\n",
    "            severity = 5  # Very negative\n",
    "\n",
    "        # Adjust for very vague/unopinionated comments\n",
    "        if subjectivity < 0.2 and sentiment == \"Neutral\":\n",
    "            severity = 2  # Informational, not severe\n",
    "\n",
    "        return sentiment, severity\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Sentiment Error]: {e}\")\n",
    "        return \"Neutral\", 3\n",
    "\n",
    "\n",
    "# === Process Each Feedback Comment ===\n",
    "results = []\n",
    "import time\n",
    "start_time= time.time()\n",
    "for _, row in tqdm(df_normal.iterrows(), total=len(df_normal)):\n",
    "    comment = row[\"Comments\"]\n",
    "    employee_id = row[\"EmployeeID\"]\n",
    "    benefit_id = row[\"BenefitID\"]\n",
    "    BenefitType = row['BenefitType']\n",
    "    BenefitSubType = row['BenefitSubType']\n",
    "    # Step 1: Category Classification\n",
    "    category = classify_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType}).strip()\n",
    "\n",
    "    # Step 2: Sentiment Analysis (local NLP)\n",
    "    sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "    # Step 3: Action Identification\n",
    "    action_output = action_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"category\": category,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"severity\": severity\n",
    "    })\n",
    "    actionable, suggested_action = \"No\", \"None\"\n",
    "    if \"Actionable:\" in action_output:\n",
    "        parts = action_output.split(\"Suggested Action:\")\n",
    "        actionable = parts[0].split(\":\")[1].strip()\n",
    "        suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "    # Step 4: Task Routing\n",
    "    route_output = route_chain.invoke({\n",
    "        \"category\": category,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"suggested_action\": suggested_action,\n",
    "        \"severity\": severity\n",
    "    })\n",
    "    try:\n",
    "        lines = route_output.split(\"\\n\")\n",
    "        department = lines[0].split(\":\")[1].strip()\n",
    "        priority = lines[1].split(\":\")[1].strip()\n",
    "    except:\n",
    "        department = \"Unknown\"\n",
    "        issue_summary = \"Parsing error\"\n",
    "        priority = \"Medium\"\n",
    "\n",
    "    # Step 5: Generate Issue Summary\n",
    "    issue_summary = issue_summary_chain.invoke({\n",
    "        \"comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"category\": category,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"severity\": severity,\n",
    "        \"suggested_action\": suggested_action\n",
    "    }).strip()\n",
    "\n",
    "    # Add to results\n",
    "    results.append({\n",
    "        \"EmployeeID\": employee_id,\n",
    "        \"BenefitID\": benefit_id,\n",
    "        \"Comments\": comment,\n",
    "        \"BenefitType\": BenefitType,\n",
    "        \"BenefitSubType\": BenefitSubType,\n",
    "        \"Category\": category,\n",
    "        \"Sentiment\": sentiment,\n",
    "        \"Severity\": severity,\n",
    "        \"Actionable\": actionable,\n",
    "        \"SuggestedAction\": suggested_action,\n",
    "        \"Department\": department,\n",
    "        \"Priority\": priority,\n",
    "        \"IssueSummary\": issue_summary\n",
    "    })\n",
    "end_time= time.time()\n",
    "print(f\"The Time Difference to run normally: {end_time- start_time}\")\n",
    "# Save final results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"feedback_chained_output.csv\", index=False)\n",
    "print(\"‚úÖ Processed feedback saved to 'feedback_chained_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0b16b-bf4c-4553-8471-64fa7f1fe281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set up your chains\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"Category\": classify_chain,\n",
    "    \"ActionResult\": action_chain,\n",
    "    \"Routing\": route_chain,\n",
    "    \"IssueSummary\": issue_summary_chain\n",
    "})\n",
    "\n",
    "SAVE_INTERVAL = 1000  # Save after every 100 rows\n",
    "OUTPUT_FILE = \"feedback_parallel_output_iter2.csv\"\n",
    "\n",
    "# === Robust Row Processor ===\n",
    "def process_row_parallel(row):\n",
    "    try:\n",
    "        comment = row[\"Comments\"]\n",
    "        employee_id = row[\"EmployeeID\"]\n",
    "        benefit_id = row[\"BenefitID\"]\n",
    "        BenefitType = row[\"BenefitType\"]\n",
    "        BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "        # Step 1: Sentiment\n",
    "        sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "        input_dict = {\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"severity\": severity,\n",
    "            \"category\": \"Unknown\",\n",
    "            \"suggested_action\": \"None\"\n",
    "        }\n",
    "\n",
    "        # Step 2: Classify (separate try to isolate LLM failure)\n",
    "        try:\n",
    "            category = classify_chain.invoke({\n",
    "                \"comments\": comment,\n",
    "                \"BenefitType\": BenefitType,\n",
    "                \"BenefitSubType\": BenefitSubType\n",
    "            }).strip()\n",
    "            input_dict[\"category\"] = category\n",
    "        except Exception as e:\n",
    "            return {\"EmployeeID\": employee_id, \"Error\": f\"Category error: {e}\"}\n",
    "\n",
    "        # Step 3: Run all in parallel\n",
    "        try:\n",
    "            output = parallel_chain.invoke(input_dict)\n",
    "        except Exception as e:\n",
    "            return {\"EmployeeID\": employee_id, \"Error\": f\"Parallel chain error: {e}\"}\n",
    "\n",
    "        # Parse ActionResult\n",
    "        action_output = output.get(\"ActionResult\", \"\")\n",
    "        actionable, suggested_action = \"No\", \"None\"\n",
    "        if \"Actionable:\" in action_output:\n",
    "            parts = action_output.split(\"Suggested Action:\")\n",
    "            actionable = parts[0].split(\":\")[1].strip()\n",
    "            suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "        input_dict[\"suggested_action\"] = suggested_action\n",
    "\n",
    "        # Re-run dependent chains\n",
    "        try:\n",
    "            routing_result = route_chain.invoke(input_dict)\n",
    "            lines = routing_result.split(\"\\n\")\n",
    "            department = lines[0].split(\":\")[1].strip() if len(lines) > 0 else \"Unknown\"\n",
    "            priority = lines[1].split(\":\")[1].strip() if len(lines) > 1 else \"Medium\"\n",
    "        except Exception as e:\n",
    "            department, priority = \"Unknown\", \"Medium\"\n",
    "\n",
    "        try:\n",
    "            issue_summary = issue_summary_chain.invoke(input_dict).strip()\n",
    "        except Exception as e:\n",
    "            issue_summary = \"Summary generation error\"\n",
    "\n",
    "        return {\n",
    "            \"EmployeeID\": employee_id,\n",
    "            \"BenefitID\": benefit_id,\n",
    "            \"Comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"Category\": category,\n",
    "            \"Sentiment\": sentiment,\n",
    "            \"Severity\": severity,\n",
    "            \"Actionable\": actionable,\n",
    "            \"SuggestedAction\": suggested_action,\n",
    "            \"Department\": department,\n",
    "            \"Priority\": priority,\n",
    "            \"IssueSummary\": issue_summary\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"EmployeeID\": row.get(\"EmployeeID\", \"Unknown\"), \"Error\": f\"Fatal row error: {e}\"}\n",
    "\n",
    "\n",
    "df_parallel = df\n",
    "rows = [row for _, row in df_parallel.iterrows()]\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "        for i, future in enumerate(tqdm(as_completed(futures), total=len(futures))):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "            # Save checkpoint every N rows\n",
    "            if i % SAVE_INTERVAL == 0 and i > 0:\n",
    "                checkpoint_df = pd.DataFrame(results)\n",
    "                checkpoint_df.to_csv(OUTPUT_FILE, index=False)\n",
    "                print(f\"üî∏ Checkpoint saved at row {i}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parallel processing failed: {e}\")\n",
    "    # Save whatever was done so far\n",
    "    pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"‚ö†Ô∏è Partial results saved after crash.\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"‚è±Ô∏è Time Taken: {end - start:.2f} seconds\")\n",
    "\n",
    "# Final save\n",
    "pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False)\n",
    "print(\"‚úÖ Final results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab449de-8219-4297-bfb4-48114e45a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 5514/29376 [27:43<1:24:11,  4.72it/s]"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"Category\": classify_chain,\n",
    "    \"ActionResult\": action_chain,\n",
    "    \"Routing\": route_chain,\n",
    "    \"IssueSummary\": issue_summary_chain\n",
    "})\n",
    "\n",
    "\n",
    "def process_row_parallel(row):\n",
    "    try:\n",
    "        comment = row[\"Comments\"]\n",
    "        employee_id = row[\"EmployeeID\"]\n",
    "        benefit_id = row[\"BenefitID\"]\n",
    "        BenefitType = row[\"BenefitType\"]\n",
    "        BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "        sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "        input_dict = {\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"severity\": severity,\n",
    "            \"category\": \"Unknown\",           # Needed by action_chain\n",
    "            \"suggested_action\": \"None\"       # Needed by route_chain & summary\n",
    "        }\n",
    "\n",
    "        # Classify first to get category\n",
    "        category = classify_chain.invoke({\n",
    "            \"comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType\n",
    "        }).strip()\n",
    "        input_dict[\"category\"] = category\n",
    "\n",
    "        # Now run the rest in parallel\n",
    "        output = parallel_chain.invoke(input_dict)\n",
    "\n",
    "        # Parse action result\n",
    "        action_output = output.get(\"ActionResult\", \"\")\n",
    "        actionable, suggested_action = \"No\", \"None\"\n",
    "        if \"Actionable:\" in action_output:\n",
    "            parts = action_output.split(\"Suggested Action:\")\n",
    "            actionable = parts[0].split(\":\")[1].strip()\n",
    "            suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "        # Update for final prompt pieces\n",
    "        input_dict[\"suggested_action\"] = suggested_action\n",
    "\n",
    "        # Re-run route and summary with full data\n",
    "        routing_result = route_chain.invoke(input_dict)\n",
    "        issue_summary = issue_summary_chain.invoke(input_dict)\n",
    "\n",
    "        # Parse routing\n",
    "        lines = routing_result.split(\"\\n\")\n",
    "        department = lines[0].split(\":\")[1].strip() if len(lines) > 0 else \"Unknown\"\n",
    "        priority = lines[1].split(\":\")[1].strip() if len(lines) > 1 else \"Medium\"\n",
    "\n",
    "        return {\n",
    "            \"EmployeeID\": employee_id,\n",
    "            \"BenefitID\": benefit_id,\n",
    "            \"Comments\": comment,\n",
    "            \"BenefitType\": BenefitType,\n",
    "            \"BenefitSubType\": BenefitSubType,\n",
    "            \"Category\": category,\n",
    "            \"Sentiment\": sentiment,\n",
    "            \"Severity\": severity,\n",
    "            \"Actionable\": actionable,\n",
    "            \"SuggestedAction\": suggested_action,\n",
    "            \"Department\": department,\n",
    "            \"Priority\": priority,\n",
    "            \"IssueSummary\": issue_summary.strip()\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "df_parallel = df\n",
    "rows = [row for _, row in df_parallel.iterrows()]\n",
    "results = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        result = future.result()\n",
    "        results.append(result)\n",
    "end = time.time()\n",
    "print(f\"The Time Taken to run in parallel:  {end- start}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"feedback_parallel_output.csv\", index=False)\n",
    "print(\"‚úÖ Done! Results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc737bb-b955-4517-bade-1afcbb055501",
   "metadata": {},
   "source": [
    "### Normal Processing: \n",
    "For 25 Feedbacks - 140 Seconds and 5.60 sec / iteration\n",
    "\n",
    "### Parallel Processing: \n",
    "For 50 Feedbacks - 24.7 Seconds and 2.02 sec / iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cc19e-469f-4f4c-b635-d67def0b9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# def process_row_parallel(row):\n",
    "#     try:\n",
    "#         comment = row[\"Comments\"]\n",
    "#         employee_id = row[\"EmployeeID\"]\n",
    "#         benefit_id = row[\"BenefitID\"]\n",
    "#         BenefitType = row[\"BenefitType\"]\n",
    "#         BenefitSubType = row[\"BenefitSubType\"]\n",
    "\n",
    "#         # 1. Local sentiment analysis\n",
    "#         sentiment, severity = analyze_sentiment(comment)\n",
    "\n",
    "#         # 2. Input to all chains\n",
    "#         shared_input = {\n",
    "#             \"comments\": comment,\n",
    "#             \"BenefitType\": BenefitType,\n",
    "#             \"BenefitSubType\": BenefitSubType,\n",
    "#             \"sentiment\": sentiment,\n",
    "#             \"severity\": severity,\n",
    "#             # suggested_action is not yet known (circular)\n",
    "#         }\n",
    "#         from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "#         parallel_chain = RunnableParallel({\n",
    "#             \"Category\": classify_chain,\n",
    "#             \"ActionResult\": action_chain,\n",
    "#             \"Routing\": route_chain,\n",
    "#             \"IssueSummary\": issue_summary_chain\n",
    "#         })\n",
    "\n",
    "#         # 3. Run all chains in parallel\n",
    "#         output = parallel_chain.invoke(shared_input)\n",
    "\n",
    "#         # Unpack results\n",
    "#         category = output.get(\"Category\", \"Other\").strip()\n",
    "#         action_result = output.get(\"ActionResult\", \"\").strip()\n",
    "#         routing_result = output.get(\"Routing\", \"\").strip()\n",
    "#         issue_summary = output.get(\"IssueSummary\", \"\").strip()\n",
    "\n",
    "#         # Parse Actionable & Suggested Action\n",
    "#         actionable, suggested_action = \"No\", \"None\"\n",
    "#         if \"Actionable:\" in action_result:\n",
    "#             parts = action_result.split(\"Suggested Action:\")\n",
    "#             actionable = parts[0].split(\":\")[1].strip()\n",
    "#             suggested_action = parts[1].strip() if len(parts) > 1 else \"None\"\n",
    "\n",
    "#         # Parse Department & Priority\n",
    "#         department = \"Unknown\"\n",
    "#         priority = \"Medium\"\n",
    "#         lines = routing_result.split(\"\\n\")\n",
    "#         if len(lines) >= 2:\n",
    "#             department = lines[0].split(\":\")[1].strip()\n",
    "#             priority = lines[1].split(\":\")[1].strip()\n",
    "\n",
    "#         return {\n",
    "#             \"EmployeeID\": employee_id,\n",
    "#             \"BenefitID\": benefit_id,\n",
    "#             \"Comments\": comment,\n",
    "#             \"BenefitType\": BenefitType,\n",
    "#             \"BenefitSubType\": BenefitSubType,\n",
    "#             \"Category\": category,\n",
    "#             \"Sentiment\": sentiment,\n",
    "#             \"Severity\": severity,\n",
    "#             \"Actionable\": actionable,\n",
    "#             \"SuggestedAction\": suggested_action,\n",
    "#             \"Department\": department,\n",
    "#             \"Priority\": priority,\n",
    "#             \"IssueSummary\": issue_summary\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return {\"Error\": str(e)}\n",
    "\n",
    "# df= df.head(50)\n",
    "# rows = [row for _, row in df.iterrows()]\n",
    "# results = []\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#     futures = [executor.submit(process_row_parallel, row) for row in rows]\n",
    "#     for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "#         result = future.result()\n",
    "#         results.append(result)\n",
    "# end = time.time()\n",
    "# print(f\"The Time Taken to run in parallel:  {end- start}\")\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"feedback_parallel_output.csv\", index=False)\n",
    "# print(\"‚úÖ Done! Results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3f739-1366-4e6f-9b0e-36ccd68bf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ab1f4-f4e1-4707-bc65-0f737e03326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42726a2-4a85-4307-8317-6e427a895b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['SuggestedAction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0e9c8-620c-4cf9-9862-99e70c0c65a4",
   "metadata": {},
   "source": [
    "### Testing the Generated Parallel Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed94e015-301c-4a45-ba30-c29d5128b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29376, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"feedback_parallel_output.csv\")\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "874002fc-3c1c-4c81-bb03-47e332858f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories: ['Benefit Value' 'Other' 'Process Issues' 'Provider Specific Complaints'\n",
      " 'Coverage Issues' 'Enrollment & Access Issues']\n",
      "Unique Sentiments: ['Positive' 'Neutral' 'Negative']\n",
      "Unique Severity: [2 1 3 4 5]\n",
      "Unique Actionables: ['No' 'Yes']\n",
      "Unique Departments: ['Benefits Administration' 'Human Resources' 'Customer Service'\n",
      " 'Life Insurance Coverage Department' 'Health Insurance Coverage'\n",
      " 'Childcare Services' 'Enrollment & Access' 'Retirement Benefits'\n",
      " 'Professional Development' 'Wellness Programs'\n",
      " 'Life Insurance Department' 'Health Insurance Coverage Team'\n",
      " 'Health Insurance Coverage Department' 'Provider Relations' 'IT Support'\n",
      " 'Finance' 'Life Insurance Coverage Team' 'Commuter Benefits Department'\n",
      " 'Enrollment & Access Issues' 'Health Insurance Claims'\n",
      " 'Benefits Management' 'Life Insurance Claims' 'Health Insurance Support'\n",
      " 'Commuter Benefits Administration']\n",
      "Unique Priority: ['Medium' 'High']\n",
      "----------------------------------------------------------\n",
      "Unique Count of SuggestedAction: 296\n",
      "Unique Count of IssueSummary: 1033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique Categories: {df['Category'].unique()}\")\n",
    "print(f\"Unique Sentiments: {df['Sentiment'].unique()}\")\n",
    "print(f\"Unique Severity: {df['Severity'].unique()}\")\n",
    "print(f\"Unique Actionables: {df['Actionable'].unique()}\")\n",
    "print(f\"Unique Departments: {df['Department'].unique()}\")\n",
    "print(f\"Unique Priority: {df['Priority'].unique()}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"Unique Count of SuggestedAction: {df['SuggestedAction'].nunique()}\")\n",
    "print(f\"Unique Count of IssueSummary: {df['IssueSummary'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "874148c5-4fac-4abb-bb78-956d34b71393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID             0\n",
      "BenefitID              0\n",
      "Comments               0\n",
      "BenefitType            0\n",
      "BenefitSubType         0\n",
      "Category               0\n",
      "Sentiment              0\n",
      "Severity               0\n",
      "Actionable             0\n",
      "SuggestedAction    13385\n",
      "Department             0\n",
      "Priority               0\n",
      "IssueSummary           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
